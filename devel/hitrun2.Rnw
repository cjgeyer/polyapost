
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{indentfirst}
\usepackage{natbib}

\newcommand{\opand}{\mathbin{\rm and}}
\newcommand{\opor}{\mathbin{\rm or}}

\DeclareMathOperator{\var}{var}

\newcommand{\real}{\mathbb{R}}

\begin{document}

\title{Design Document for Hit and Run Function, Version 2}

\author{Charles J. Geyer}

\maketitle

\section{The Problem} \label{sec:problem}

The problem is to simulate a linear equality and linear inequality constrained
Dirichlet distribution.  The method of simulation is Markov chain Monte Carlo
using the hit-and-run algorithm.

The R package \texttt{polyapost}, version 1.2-1 (which is not on CRAN),
has a function \texttt{hitrun} that implements this algorithm
but has several issues.
This function does not work for high-dimensional problems
because it uses too much
computational geometry, in particular, in finding the vertices of the support
of the distribution (a convex polytope) using the R function \texttt{scdd}
in the R package \texttt{rcdd}.  This operation is scaling-hostile,
because the number of vertices of a polytope
can be exponential in the dimension (a hypercube of dimension $d$, for example, 
has $2^d$ vertices).  Thus we need to redesign the \texttt{hitrun} function
so it avoids the operation of finding the vertices.

\section{Example}

We do an example with
<<d>>=
d <- 10
@
dimensions.  Suppose we observe data having a probability distribution
on a state space having $d$ points, which we take to be
\begin{equation} \label{eq:state-space}
   D = \{ 1, \ldots, d \}
\end{equation}
And suppose we want to do Bayesian inference.  The parameter
vector is the probability vector $p$ on these points.   We have, of
course, the constraints that the probabilities are nonnegative and
sum to one ($d$ inequality constraints and 1 equality constraint),
but suppose we also want both the mean and the median to be exactly
$(d + 1) / 2$.

The mean constraint is an equality constraint
$$
   \sum_{k = 1}^d k p_k = \frac{d + 1}{2}.
$$
The median constraint is two inequality constraints
\begin{align*}
   \sum_{k = 1}^{\lceil (d + 1) / 2 \rceil - 1} p_k \le \frac{1}{2}
   \\
   \sum_{k = \lfloor (d + 1) / 2 \rfloor + 1}^d p_k \le \frac{1}{2}
\end{align*}
In case $d$ is even, so $(d + 1) / 2$ is not an integer, these two
constraints must actually be satisfied with equality because of the
constraint that the probabilities sum to one.
In case $d$ is odd, so $(d + 1) / 2$ is an integer, these two
constraints can be satisfied with inequality, so stay inequalities.
We can always specify them as inequality constraints and leave it to
the \texttt{linearity} function to figure out when they must be equality
constraints.

And suppose we want the median absolute deviation to be at least
<<r>>=
r <- floor((d - 1) / 4)
@
That gives us one inequality constraint
$$
   \sum_{k = 1}^{\lfloor (d + 1) / 2 - r \rfloor} p_k
   +
   \sum_{k = \lceil (d + 1) / 2 + r \rceil}^d p_k
   \ge
   \frac{1}{2}
$$

\section{Computational Geometry}

Before we can simulate we must do a dimension reduction,
finding the dimension of the convex polytope and finding a coordinate
system in which the convex polytope has full dimension.
To do that, we use functions
in the R package \texttt{rcdd}, which does computational geometry.

We express the inequality constraints as $A_1 p \le b_1$,
where $A_1$ is a matrix, $b_1$ a vector,
and the inequality operates componentwise,
and we express the equality constraints as $A_2 p = b_2$, where $A_2$ is
a matrix, $b_2$ a vector.
<<cons>>=
i <- 1:d
a2 <- rbind(rep(1, d), i)
b2 <- c(1, (d + 1) / 2)
a1 <- - diag(d)
b1 <- rep(0, d)
a1 <- rbind(a1, as.numeric(2 * i < d + 1), as.numeric(2 * i > d + 1))
b1 <- c(b1, 1 / 2, 1 / 2)
a1 <- rbind(a1, - as.numeric(i <= (d + 1) / 2 - r) -
    as.numeric(i >= (d + 1) / 2 + r))
b1 <- c(b1, - 1 / 2)
@
Now we dump this into \texttt{rcdd}.  The constraint set is represented
by constraints as an H-representation.  The function \texttt{makeH} makes
that.
<<hrep>>=
library(rcdd)
hrep1 <- makeH(a1, b1, a2, b2)
hrep1
@
The first column is a code: 1 indicates an equality constraint,
0 indicates an inequality constraint.  The second column is the right-hand
side vector.  The rest of each row is the negative of some row of $A_1$
or $A_2$.

\subsection{Implied Equality Constraints}

We now do an operation that is needed for this example when $d$ is even
but not when $d$ is odd.  It is needed if we allow the user to input
general constraint matrices and vectors.
This is determination of the putative inequality constraints that actually
hold with equality at all points in the constraint set.
<<hrep-too>>=
lout <- linearity(d2q(hrep1))
is.equality <- hrep1[ , 1] == 1
is.equality[lout] <- TRUE
is.equality
@
The constraints that hold with equality (both the ones that were given
as equality constraints and the ones that were given as inequality constraints
but the \texttt{linearity} function discovered actually hold with equality)
are the ones with the corresponding components of \texttt{is.equality} equal
to \texttt{TRUE}.

Note the operation \texttt{d2q} which provides the H-representation as
GMP (GNU multiple precision) rational values, and makes the \texttt{linearity}
function use infinite precision rational arithmetic.  Hence our computation is
exact.  We use exact rational arithmetic until further notice.

We make a new H-representation with the implied equality constraints
changed to explicit equality constraints.
<<hrep2>>=
hrep2 <- d2q(hrep1)
hrep2[is.equality , 1] <- "1"
hrep2
@

Now we need to deal with equality constraints and inequality constraints
separately.
<<sep>>=
hrep3 <- hrep2[hrep2[ , 1] == "1", , drop = FALSE]
hrep4 <- hrep2[hrep2[ , 1] == "0", , drop = FALSE]
@

\subsection{Change of Variable} \label{sec:change}

\subsubsection{V-Representation}

The equality constraints give us the affine hull of the polytope.
We want to switch from an H-representation of the affine hull (the
equality constraints) to a V-representation (a point in the affine
hull and a set of basis vectors for the tangent space of the affine hull,
the vector space parallel to it).  The R function \texttt{scdd} in
the R package \texttt{rcdd} does this operation.
<<affine-hull>>=
vrep3 <- scdd(hrep3, representation = "H")$output
vrep3
is.line <- vrep3[ , 1] == "1" & vrep3[ , 2] == "0"
is.point <- vrep3[ , 1] == "0" & vrep3[ , 2] == "1"
all(is.point | is.line)
sum(is.point) == 1
@
The codes in the first and second columns are 0 and 1 (in that order) for
points and 1 and 0 (in that order) for directions.  The affine hull of the
convex polytope
is the vector subspace spanned by the directions
translated by the point.  We should have one point and all the rest lines
(directions).  (There are two other codes --- 0 and 0 for rays and 1 and 1
for affine generators --- but we should never have either of them.)
<<coordinates>>=
foo <- vrep3[ , - c(1, 2), drop = FALSE]
origin <- foo[is.point, ]
basis <- foo[is.line, , drop = FALSE]
basis <- t(basis)
origin
basis
@
(the transpose is because we want the columns of the matrix \texttt{basis}
to be the basis vectors).
If we denote the vector \texttt{origin} as $u$ and the matrix \texttt{basis}
as $V$, then the transformation $x \mapsto u + V x$ maps
\Sexpr{ncol(basis)}-dimensional space to the affine hull of the convex
polytope in \Sexpr{nrow(basis)}-dimensional space.  We say this transformation
maps ``new coordinates'' to ``old coordinates.''

\subsection{Inequality Constraints in New Coordinates}

The change of variable takes care of the equality constraints.  By
construction $u + V x$ satisfies the equality constraints (in old coordinates)
for all $x$ (for all points in new coordinates).

We now need to make the inequality constraints refer to the new coordinate
system.  If the constraints are $A y \le b$ in the old coordinate system,
then they are $A(u + V x) \le b$ in the new coordinate system, or,
what is equivalent $A V x \le b - A u$.  Thus we need to construct
the matrix $A V$ and the vector $b - A u$.
<<ineq>>=
amat <- qneg(hrep4[ , - c(1, 2), drop = FALSE])
bvec <- hrep4[ , 2]
bvec <- qmq(bvec, qmatmult(amat, cbind(origin)))
amat <- qmatmult(amat, basis)
@

Some of these constraints may be redundant --- implied by some of the
others --- but that is o.~k.  Eliminating redundant constraints is more
trouble than it is worth.  It can be exceedingly time consuming to eliminate
them.  Having redundant inequality constraints that are truly inequality
constraints (which has been assured by our use of the \texttt{linearity}
function), does not affect the correctness of the hit-and-run algorithm.
The redundant constraints have no effect, and checking them only slows
down the hit-and-run algorithm by a little bit.

\subsection{Log Unnormalized Density Function in New Coordinates}

The log unnormalized density function in old coordinates is
$$
   h_{\text{old}}(y) = \sum_{i = 1}^d (\alpha_i - 1) \log(y)
$$
We must have $y_i > 0$ for all components of $y$ for this to make sense.
However, using inexact computer arithmetic we could get very small negative
$y_i$ and hence have to deal with that.  The right thing to do is return
\verb@-Inf@.  This will cause this proposal to be rejected in the Metropolis
algorithm.

The log unnormalized density function in new coordinates is
$$
   h_{\text{new}}(x) = h_{\text{old}}(u + V x)
$$
where $u$ and $V$ are as defined in Section~\ref{sec:change} and are
called \texttt{origin} and \texttt{basis}, respectively, in R and C code.
This will work correctly with inexact computer arithmetic if $h_{\text{old}}$
is defined so as to work correctly, as explained in the preceding paragraph.

\subsection{Output Function in New Coordinates}

The output function in old coordinates is
$$
   f_{\text{old}}(y) = O y
$$
where $O$ is the matrix \texttt{outmat} in R and C code.
Hence in new coordinates it is
$$
   f_{\text{new}}(y) = O (u + V x) = O u + O V x
$$
where, as in the preceding section, $u$ and $V$ are as defined in
Section~\ref{sec:change}.

\subsection{Initial State}

There is one remaining issue involving computational geometry:
finding a starting point for the Markov chain if one is not supplied,
which can be any point in the constraint set (in new coordinates).

This is the point where the R function \texttt{hitrun} from the
aforementioned R package \texttt{polyapost}, version 1.2-1 finds the
vertices of the support of the distribution (a convex polytope) in the
new coordinates.  And this is the operation that does not scale and
can take hours, days, arbitrarily long, really, for high-dimensional
problems.

So we use a different strategy, linear programming.  To do this we solve
the following linear program
\begin{align*}
    \text{\normalfont maximize} & \quad e
    \\
    \text{\normalfont subject to} & \quad A x + e \le b
\end{align*}
in which the state is the vector $(x, e)$ where $x$ is the state of the
given problem (in new coordinates) and $e$ is another scalar variable,
and in which the inequality is interpreted coordinatewise.
Given that we know that none of the inequality constraints is an implied
equality constraint it must be that there exist points $x$ such that
$A x < b$ (where, again, inequality is interpreted coordinatewise)
holds hence $A x + e \le b$ holds for some strictly positive $e$,
assuming that the constraint set is actually nonempty.
The linear program then finds $x$ and $e$ such that $e$ is as large as
possible, thus finding the relative interior point that is farthest from
the boundary.
<<lp>>=
hrep5 <- cbind("0", bvec, qneg(amat), "-1")
grad5 <- c(rep("0", ncol(amat)), "1")
lout <- lpcdd(hrep5, grad5, minimize = FALSE)
names(lout)
lout$solution.type
lout$optimal.value
@
If \verb@lout$solution.type@ is \verb@"Optimal"@
and \verb@lout$optimal.value@ is a positive number, then we have found
a point in the relative interior of the convex polytope (in new coordinates).
Otherwise the convex polytope is
the empty set (the constraints are inconsistent), in which case we have to
give an error message (the user has specified the problem incorrectly).

When we have an optimal solution (a point in the polytope), it is
<<lp-point>>=
x <- lout$primal.solution
x <- x[- length(x)]
x
@
(a point in new coordinates).

Let us check that this point does satisfy the constraints
<<relative-interior-check>>=
qmq(bvec, as.vector(qmatmult(amat, cbind(x))))
@
All constraints are indeed slack.  The point \texttt{x} is in the
relative interior of the constraint set in the new coordinates.
It is a possible starting value for the Markov chain.

\subsection{Conversion from Rational to Floating Point}

Now we convert the arguments to the MCMC function to conventional
computer so-called real numbers.
<<convert>>=
origin <- q2d(origin)
basis <- q2d(basis)
bvec <- q2d(bvec)
amat <- q2d(amat)
x <- q2d(x)
bvec
amat
round(x, 4)
@

\section{Hit-and-Run Sampler}

How does hit-and-run work?  It generates a random direction (we use the
direction along a mean-zero normal random vector), then calculates the
section of the line through the current position in that direction that
lies in the constraint set (the constraint set in the new coordinates
determined by \texttt{amat} and \texttt{bvec}).

\subsection{Proposal Line Segment}

To calculate the proposal, we need to know
the maximum and minimum values of $s$ such that
$$
   A (x + s z) \le b
$$
holds where $x$ is the current position and $z$ is the mean-zero normal
random vector.  Since this is the same as
$$
   s A z \le b - A x
$$
we find the range of $s$ values such that this holds.
Write
\begin{align*}
   q & = A z
   \\
   r & = b - A x
\end{align*}
so the inequalities are
\begin{equation} \label{eq:ineq}
   s q_i \le r_i, \qquad i = 1, \ldots, n
\end{equation}
where $n$ is the row dimension of \texttt{amat} and the length
of \texttt{bvec}.
We know that the current state $x$ satisfies the constraints $A x \le b$,
hence \eqref{eq:ineq} is satisfied when $s = 0$.  When $q_i < 0$ dividing
through by $q_i$ reverses the inequality, thus the inequalities \eqref{eq:ineq}
become
\begin{align*}
   s & \le r_i / q_i, \qquad i \in D \opand q_i > 0
   \\
   s & \ge r_i / q_i, \qquad i \in D \opand q_i < 0
\end{align*}
(where $D$ is given by \eqref{eq:state-space}).  So, defining
\begin{align*}
   s_{\text{max}} & = \min_{\substack{i \in D \\ q_i > 0}} \frac{r_i}{q_i}
   \\
   s_{\text{min}} & = \max_{\substack{i \in D \\ q_i < 0}} \frac{r_i}{q_i}
\end{align*}
the set of points of the form $x + s z$ that lie in the convex polytope
are those for which $s_{\text{min}} \le s \le s_{\text{max}}$.
And (as mentioned above) we always have $s_{\text{min}} < 0 < s_{\text{max}}$.

\subsection{Proposal Direction Distribution}

The proposal direction distribution does not matter, so long as it proposes
directions that span the space (of new coordinates).  At least it does not
affect the correctness of the hit-and-run algorithm.  It may affect the
efficiency (how long one needs to run the sample to get a certain accuracy
of estimation).  For now we just use a standard multivariate normal
distribution (mean vector zero, variance matrix the identity)
in new coordinates.

\begin{thebibliography}{}

\bibitem[Geyer and Meeden(2013)]{geyer-meeden}
Geyer, C.~J. and Meeden, G.~D. (2013).
\newblock Asymptotics for constrained Dirichlet distributions.
\newblock \emph{Bayesian Analysis}, \textbf{8}, 89--110.

\end{thebibliography}

\end{document}

\begin{center} \LARGE REVISED DOWN TO HERE \end{center}

