
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{indentfirst}

\newcommand{\opand}{\mathbin{\rm and}}
\newcommand{\opor}{\mathbin{\rm or}}

\begin{document}

\title{Design Document for Hit and Run Function, Version 2}

\author{Charles J. Geyer}

\maketitle

\section{The Problem} \label{sec:problem}

The problem is to simulate a linear equality and linear inequality constrained
Dirichlet distribution.  The method of simulation is Markov chain Monte Carlo
using the hit and run algorithm.

Version 1 of the algorithm (the R function \texttt{hitrun} in the
R package \texttt{polyapost}) did not scale well because it used too much
computational geometry, in particular finding the vertices of the support
of the distribution (a convex polytope) using the R function \texttt{scdd}
in the R package \texttt{rcdd}.  This does not scale because the number
of vertices can be exponential in the dimension of the state vector and
the number of constraints.  In this version, we will allow the use of the
R functions \texttt{redundant} and \texttt{lpcdd} in the R package
\texttt{rcdd}, which find implied equality constraints (inequality constraints 
that actually must be satisfied with equality) and drop redundant constraints
(function \texttt{redundant}) and do linear programming (\texttt{lpcdd}),
but no other functions from the R package \texttt{rcdd}.

Version 1 of the algorithm also uses a distribution on directions (about
which see below) that is chosen arbitrarily and is uncontrollable by the
user.  We add user control to allow a reasonably chosen proposal distribution.

\section{Example}

We do an example with
<<d>>=
d <- 10
@
dimensions.  Suppose we observe data having a probability distribution
on a state space having $d$ points, which we take to be
\begin{equation} \label{eq:state-space}
   D = \{ 1, \ldots, d \}
\end{equation}
And suppose we want to do Bayesian inference.  The parameter
vector is the probability vector $p$ on these points.   We have, of
course, the constraints that the probabilities are nonnegative and
sum to one ($d$ inequality constraints and 1 equality constraint),
but suppose we also want both the mean and the median to be exactly
$(d + 1) / 2$.

The mean constraint is an equality constraint
$$
   \sum_{k = 1}^d k p_k = \frac{d + 1}{2}.
$$
The median constraint is two inequality constraints
\begin{align*}
   \sum_{k = 1}^{\lceil (d + 1) / 2 \rceil - 1} p_k \le \frac{1}{2}
   \\
   \sum_{k = \lfloor (d + 1) / 2 \rfloor + 1}^d p_k \le \frac{1}{2}
\end{align*}
In case $d$ is even, so $(d + 1) / 2$ is not an integer, these two
constraints must actually be satisfied with equality because of the
constraint that the probabilities sum to one.
In case $d$ is odd, so $(d + 1) / 2$ is an integer, these two
constraints can be satisfied with inequality, so stay inequalities.
We can always specify them as inequality constraints and leave it to
the \texttt{redundant} function to figure out when they must be equality
constraints.

And suppose we want the median absolute deviation to be at least
<<r>>=
r <- floor((d - 1) / 4)
@
That gives us one inequality constraint
$$
   \sum_{k = 1}^{\lfloor (d + 1) / 2 - r \rfloor} p_k
   +
   \sum_{k = \lceil (d + 1) / 2 + r \rceil}^d p_k
   \ge
   \frac{1}{2}
$$

\section{Computational Geometry}

Before we can simulate we must do a dimension reduction,
finding the dimension of the convex polytope and finding a coordinate
system in which the convex polytope has full dimension.  We use functions
in the R package \texttt{rcdd}, which does computational geometry.

We express the inequality constraints as $A_1 p \le b_1$,
where $A_1$ is a matrix, $b_1$ a vector,
and the inequality operates componentwise,
and we express the equality constraints as $A_2 p = b_2$, where $A_2$ is
a matrix, $b_2$ a vector.
<<cons>>=
i <- 1:d
a2 <- rbind(rep(1, d), i)
b2 <- c(1, (d + 1) / 2)
a1 <- - diag(d)
b1 <- rep(0, d)
a1 <- rbind(a1, as.numeric(2 * i < d + 1), as.numeric(2 * i > d + 1))
b1 <- c(b1, 1 / 2, 1 / 2)
a1 <- rbind(a1, - as.numeric(i <= (d + 1) / 2 - r) -
    as.numeric(i >= (d + 1) / 2 + r))
b1 <- c(b1, - 1 / 2)
@
Now we dump this into \texttt{rcdd}.  The constraint set is represented
by constraints as an H-representation.  The function \texttt{makeH} makes
that.
<<hrep>>=
library(rcdd)
hrep1 <- makeH(a1, b1, a2, b2)
hrep1
@
The first column is a code: 1 indicates an equality constraint,
0 indicates an inequality constraint.  The second column is the right-hand
side vector.  The rest of each row is the negative of some row of $A_1$
or $A_2$.

\subsection{Eliminating Redundant Constraints}

We now do an operation that is needed for this example when $d$ is even
but not when $d$ is odd.  It is needed if we allow the user to input
general constraint matrices and vectors.
This is elimination of redundant constraints from the H-representation.
<<hrep-too>>=
rout <- redundant(d2q(hrep1))
hrep2 <- rout$output
identical(rout$new.position, 1:nrow(hrep1))
@
If the last statement says \texttt{TRUE}, then this operation is a no op
(does nothing); otherwise changes have been made.
<<hrep-too-show>>=
hrep2
@
The reason why this matrix now has character-valued components is that
we have switched to exact rational arithmetic (following the advice
of the R package \texttt{rcdd}) so our results are exact.  We stay in
exact rational arithmetic until further notice.

We see that where we formerly had \Sexpr{nrow(hrep1)} constraints in all
we now have \Sexpr{nrow(hrep2)}.
The former inequality constraints that have been found to actually hold
with equality are
<<hrep-too-show-too>>=
rout$implied.linearity
@
and the dropped constraints were the former constraints numbered
<<hrep-too-show-too-too>>=
seq(along = rout$new.position)[rout$new.position == 0]
@

Now we need to deal with equality constraints and inequality constraints
separately.
<<sep>>=
hrep3 <- hrep2[hrep2[ , 1] == "1", , drop = FALSE]
hrep4 <- hrep2[hrep2[ , 1] == "0", , drop = FALSE]
@

\subsection{Change of Variable} \label{sec:change}

The equality constraints give us the affine hull of the polytope.
Actually, we lied in Section~\ref{sec:problem}.  We will never use
the R function \texttt{scdd} in the R package \texttt{rcdd} on the
polytope, that is, we will not do \texttt{scdd(hrep2)}, but it is
safe to do it here, where it just finds point in the affine hull and
a basis for the tangent space of the affine hull (the vector space
parallel to it).
<<affine-hull>>=
vrep3 <- scdd(hrep3, representation = "H")$output
vrep3
is.line <- vrep3[ , 1] == "1" & vrep3[ , 2] == "0"
is.point <- vrep3[ , 1] == "0" & vrep3[ , 2] == "1"
all(is.point | is.line)
sum(is.point) == 1
sum(is.line) == d - nrow(hrep3)
@
The codes in the first and second columns are 0 and 1 (in that order) for
points and 1 and 0 (in that order) for directions.  The affine hull of the
convex polytope
is the vector subspace spanned by the directions
translated by the point.
<<coordinates>>=
foo <- vrep3[ , - c(1, 2), drop = FALSE]
origin <- foo[is.point, ]
basis <- foo[is.line, , drop = FALSE]
basis <- t(basis)
origin
basis
@
(the transpose is because we want the columns of the matrix \texttt{basis}
to be the basis vectors).
If we denote the vector \texttt{origin} as $u$ and the matrix \texttt{basis}
as $V$, then the transformation $x \mapsto u + V x$ maps
\Sexpr{ncol(basis)}-dimensional space to the affine hull of the convex
polytope.

\subsection{Inequality Constraints in New Coordinates}

The change of variable takes care of the equality constraints.  By
construction $u + V x$ satisfies the equality constraints for all $x$.

We now need to make the inequality constraints refer to the new coordinate
system.  If the constraints are $A y \le b$ in the old coordinate system,
then they are $A(u + V x) \le b$ in the new coordinate system, or,
what is equivalent $A V x \le b - A u$.  Thus we need to construct
the matrix $A V$ and the vector $b - A u$.
<<ineq>>=
amat <- qneg(hrep4[ , - c(1, 2), drop = FALSE])
bvec <- hrep4[ , 2]
bvec <- qmq(bvec, qmatmult(amat, cbind(origin)))
amat <- qmatmult(amat, basis)
@

\subsection{Log Unnormalized Density Function in New Coordinates}

The log unnormalized density function in old coordinates is
$$
   h_{\text{old}}(y) = \sum_{i = 1}^d (\alpha_i - 1) \log(y)
$$
We must have $y_i > 0$ for all components of $y$ for this to make sense.
However, using inexact computer arithmetic we could get very small negative
$y_i$ and hence have to deal with that.  The right thing to do is return
\verb@-Inf@.  This will cause this proposal to be rejected in the Metropolis
algorithm.

The log unnormalized density function in new coordinates is
$$
   h_{\text{new}}(x) = h_{\text{old}}(u + V x)
$$
where $u$ and $V$ are as defined in Section~\ref{sec:change} and are
called \texttt{origin} and \texttt{basis}, respectively, in R and C code.
This will work correctly with inexact computer arithmetic if $h_{\text{old}}$
is defined so as to work correctly, as explained in the preceding paragraph.

\subsection{Output Function in New Coordinates}

The output function in old coordinates is
$$
   f_{\text{old}}(y) = O y
$$
where $O$ is the matrix \texttt{outmat} in R and C code.
Hence in new coordinates it is
$$
   f_{\text{new}}(y) = O (u + V x) = O u + O V x
$$
where, as in the preceding section, $u$ and $V$ are as defined in
Section~\ref{sec:change}.

\subsection{Initial State}

There is one remaining issue involving computational geometry:
finding a starting point for the Markov chain if one is not supplied,
which can be any point in the constraint set (in new coordinates).

This is the point where Version~1 of the \texttt{hitrun} function used
the R function \texttt{scdd} in the R package \texttt{rcdd} to find the
vertices of the support of the distribution (a convex polytope) in the
new coordinates.  And this is the operation that does not scale and
can take hours, days, arbitrarily long, really, for high-dimensional
problems.

So we use a different strategy, linear programming.

<<lp>>=
hrep5 <- cbind("0", bvec, qneg(amat))
grad5 <- rep("0", ncol(amat))
lout <- lpcdd(hrep5, grad5)
names(lout)
lout$solution.type
@
If the last statement prints \verb@"Optimal"@, then we have found a point
in the polytope.
If the last statement prints \verb@"Inconsistent"@, then the polytope is
the empty set (the constraints are inconsistent), in which case we have to
give an error message (the user has specified the problem incorrectly).

When we have an optimal solution (a point in the polytope), it is
<<lp-point>>=
x <- lout$primal.solution
x
y <- qpq(origin, qmatmult(basis, cbind(x)))
y
@
($x$ is this point in new coordinates, $y$ is this point in old coordinates).

Glen Meeden expressed concern about starting points like this that are
on the boundary of the polytope.  It can take the hit and run sampler
a long time to ``get started'' because when at a vertex with a narrow
(solid) angle, it can take a long time to ``propose'' a direction in
which the sampler can actually move.

Thus we look for a relative interior point.  Let us find a new point
that maximizes the sum of the old coordinates that were zero at the point
already found
<<lp-too>>=
grad.old <- as.numeric(y == 0)
grad.new <- qmatmult(rbind(grad.old), basis)
grad.new <- as.vector(grad.new)
lout <- lpcdd(hrep5, grad.new, minimize = FALSE)
lout$solution.type
x1 <- lout$primal.solution
x1
y1 <- qpq(origin, qmatmult(basis, cbind(x1)))
y1
@
So now we have found two points in the convex polytope, and, because of
convexity, an infinite number of points (every point on the line segment
connecting the two points we have found).
<<lp-save>>=
x <- rbind(x, x1)
y <- rbind(y, y1)
x
y
@
We see we still have some components of the state vector that will be
zero at all starting points we now know, so we repeat the previous operation.
<<lp-too-too>>=
grad.old <- as.numeric(apply(y == 0, 2, all))
grad.old
grad.new <- qmatmult(rbind(grad.old), basis)
grad.new <- as.vector(grad.new)
lout <- lpcdd(hrep5, grad.new, minimize = FALSE)
lout$solution.type
x1 <- lout$primal.solution
x1
y1 <- qpq(origin, qmatmult(basis, cbind(x1)))
y1
@

Now considering the three points we have found
<<lp-save>>=
x <- rbind(x, x1)
y <- rbind(y, y1)
x
y
@
They are the vertices of a triangle, all of which is in the convex polytope,
and this triangle does have points having no old coordinates equal to zero.
We take the average of the points found
<<lp-average>>=
xave <- qdq(apply(x, 2, qsum), rep(nrow(x), ncol(x)))
xave
yave <- qpq(origin, qmatmult(basis, cbind(xave)))
yave
@
Let us check that this point does satisfy the constraints
<<lp-average-check>>=
qmq(as.vector(qmatmult(d2q(a1), cbind(yave))), b1)
qmq(as.vector(qmatmult(d2q(a2), cbind(yave))), b2)
@
The equality constraints do hold with equality, and the inequality constraints
hold with strict inequality except for the two that the \texttt{redundant}
function found to be implied equality constraints.

The point \texttt{xave} is in the
relative interior of the constraint set in the new coordinates.
It is a possible starting value for the Markov chain.

\subsection{Conversion from Rational to Floating Point}

Now we convert the arguments to the MCMC function to conventional
computer so-called real numbers.
<<convert>>=
origin <- q2d(origin)
basis <- q2d(basis)
bvec <- q2d(bvec)
amat <- q2d(amat)
x <- q2d(xave)
bvec
amat
round(x, 4)
@

\section{Hit and Run Sampler}

How does hit and run work?  It generates a random direction (we use the
direction along a mean-zero normal random vector), then calculates the
section of the line through the current position in that direction that
lies in the constraint set (the constraint set in the new coordinates
determined by \texttt{amat} and \texttt{bvec}).

\subsection{Proposal Line Segment}

To calculate the proposal, we need to know
the maximum and minimum values of $s$ such that
$$
   A (x + s z) \le b
$$
holds where $x$ is the current position and $z$ is the mean-zero normal
random vector.  Since this is the same as
$$
   s A z \le b - A x
$$
we find the range of $s$ values such that this holds.
Write
\begin{align*}
   q & = A z
   \\
   r & = b - A x
\end{align*}
so the inequalities are
\begin{equation} \label{eq:ineq}
   s q_i \le r_i, \qquad i = 1, \ldots, n
\end{equation}
where $n$ is the row dimension of \texttt{amat} and the length
of \texttt{bvec}.
We know that the current state $x$ satisfies the constraints $A x \le b$,
hence \eqref{eq:ineq} is satisfied when $s = 0$.  When $q_i < 0$ dividing
through by $q_i$ reverses the inequality, thus the inequalities \eqref{eq:ineq}
become
\begin{align*}
   s & \le r_i / q_i, \qquad i \in D \opand q_i > 0
   \\
   s & \ge r_i / q_i, \qquad i \in D \opand q_i < 0
\end{align*}
(where $D$ is given by \eqref{eq:state-space}).  So, defining
\begin{align*}
   s_{\text{max}} & = \min_{\substack{i \in D \\ q_i > 0}} \frac{r_i}{q_i}
   \\
   s_{\text{min}} & = \max_{\substack{i \in D \\ q_i < 0}} \frac{r_i}{q_i}
\end{align*}
the set of points of the form $x + s z$ that lie in the convex polytope
are those for which $s_{\text{min}} \le s \le s_{\text{max}}$.
And (as mentioned above) we always have $s_{\text{min}} < 0 < s_{\text{max}}$.

\subsection{Proposal Direction}

And how do we choose the mean-zero normal distribution for
the proposal direction?  In Version~1 of the \texttt{hitrun} function,
for the convenience of the programmer, a (multivariate) standard normal
distribution was used.  This is standard normal in the new coordinates,
and since many things about the new coordinates are arbitrary (there
are many ways to parameterize and affine set), this choice is also arbitrary.
It is merely a TTD (thing to do).  It has no other desirable properties.

Here we try to allow the use of better proposal distributions.  Since we
cannot understand the constraint fully (for example, we no longer can
calculate the vertices, because that does not scale), the computer cannot
automatically choose the proposal direction variance matrix.  Perhaps
the user can specify something, especially using information from previous
runs of the sampler.  The empirical variance of the state vector perhaps?

We have the problem of going from the old coordinates, which are the only
ones users see and understant, to the new coordinates, which is what the
computer uses.  A variance can be thought of as either a matrix or as
a quadratic form.  If $M$ is the variance matrix of the random vector $X$,
then the quadratic form is
$$
   b \mapsto b^T M b = \var(b^T X)
$$


\end{document}

\begin{center} \LARGE REVISED DOWN TO HERE \end{center}

