
\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{indentfirst}
\usepackage{natbib}

\newcommand{\opand}{\mathbin{\rm and}}
\newcommand{\opor}{\mathbin{\rm or}}

\DeclareMathOperator{\var}{var}

\newcommand{\real}{\mathbb{R}}

%\VignetteEngine{knitr::knitr}

\begin{document}

\title{Design Document for Hit and Run Function, Version 4}

\author{Charles J. Geyer}

\maketitle

<<dopoptions,include=FALSE,echo=FALSE>>=
# options(width = 70)
@

\section{R}

\begin{itemize}
\item The version of R used to make this document is \Sexpr{getRversion()}.
\item The version of the \texttt{knitr} package used to make this document is
   \Sexpr{packageVersion("knitr")}.
\item The version of the \texttt{rcdd} package used to make this document is
   \Sexpr{packageVersion("rcdd")}.
\item The version of the \texttt{polyapost} package used to make this
   document is \Sexpr{packageVersion("polyapost")}.
\end{itemize}
<<package-required>>=
library("polyapost")
stopifnot(packageVersion("rcdd") >= "1.2")
@

\section{The Problem} \label{sec:problem}

The problem is to simulate a linear equality and linear inequality constrained
Dirichlet distribution.  The method of simulation is Markov chain Monte Carlo
using the hit-and-run algorithm.

\subsection{New Issue}

The CRAN package \texttt{polyapost}, version 1.4-3
has a function \texttt{hitrun} that implements this algorithm
but has one complex issue to be resolved.

Infrequently, this function stops with the error
\begin{verbatim}
"log unnormalized density -Inf at initial state"
\end{verbatim}
This error is essential for the operation of the Metropolis rejection
that allows us to use sample a non-uniform distribution with the hit and
run algorithm.

It seems from some debugging of one instance of this error that it results
from having a very ill-conditioned basis for the tangent space of the
affine hull of the constraint set --- so ill-conditioned that conversion
to IEEE doubles and back to GMP rational results in large errors.

A very ill-conditioned basis was probably always the Wrong Thing
because \texttt{hitrun} uses a standard normal random vector as the
direction proposal \emph{in this basis} (Section~\ref{sec:proposal} below),
and that is probably a bad
proposal distribution when this basis is ill-conditioned.

In an attempt to fix this, a new function \texttt{qgram}, which provides
an orthogonal basis for a vector space, has been added to
package \texttt{rcdd}.  We can use this to find a well-conditioned basis.

We can hope this also ameliorates the problem of a point that is inside
the relative interior of the constraint set when we originally find it
using exact rational arithmetic is outside the constraint set when we convert
to IEEE double numbers.

\subsection{Old Issues}

\subsubsection{Implied Equality Constraints}

Using the R function \texttt{linearity} in package \texttt{rcdd} inside
the R function \texttt{hitrun} in this package to determine implied equality
constraints is the Wrong Thing if this step can be avoided.  It is very
time consuming; one example using 1000 variables took 3 days to do.

So we need to keep the idea of checking for the existence of
implied equality constraints before trying to calculate them.
This is already in the current version, but it needs to be combined
with the ideas in the preceeding section.

If the user just happens to supply a specification of the constraint
set that has no implied equality constraints (only explicit equality
constraints), the \texttt{linearity} step can be skipped.
We check whether or not there are any implied equality constraints by doing
one linear program.
The constraint set is the set of vectors $y$ satisfying the linear equality
and inequality constraints
\begin{equation} \label{eq:constraints}
\begin{split}
    A_1 y & \le b_1
    \\
    A_2 y & = b_2
\end{split}
\end{equation}
where equality and inequality operate coordinatewise as in R.  Here we consider
the inequality constraints to include the constraints that all components of
$y$ are nonnegative and the equality constraints to include the constraint
that the components of $y$ sum to one (which is not the case for the arguments
\texttt{a1}, \texttt{b1}, \texttt{a2}, and \texttt{b2} supplied to the
\texttt{hitrun} function, where the nonnegativity and sum-to-one constraints
are not supplied by the user but rather added by the function itself).

We wish to know whether there exists a $y$ such that the the inequality
constraints actually hold strictly
\begin{align*}
    A_1 y & < b_1
    \\
    A_2 y & = b_2
\end{align*}
and we can find such a point, if it exists, by solving the following linear
program, the state variables of which are the components of $y$ and an
additional variable $e$
\begin{equation} \label{eq:linprog-one}
\begin{split}
   \text{\normalfont maximize} & \quad e
   \\
   \text{\normalfont subject to} & \quad A_1 y + e \le b_1
   \\
                                 & \quad A_2 y \le b_2
\end{split}
\end{equation}
If the solution exists and the optimal value is strictly greater than zero,
then the point $y$ does satisfy all the inequality constraints with strict
inequality and there can be no implied equality constraints.
In that case, the \texttt{linearity} step is skipped.  Otherwise, it must be
done.

\subsubsection{Other Old Issues}

For completeness this document describes
all the procedures used by the \texttt{hitrun} function so it supersedes
previous versions of this document.  It does not give all of the arguments
for what it does that appeared in previous versions of this document.

\section{Example}

Suppose we observe data having a probability distribution
on a state space having $d$ points, which we take to be
\begin{equation} \label{eq:state-space}
   D = \{ 1, \ldots, d \}
\end{equation}
And suppose we want to do Bayesian inference.  The parameter
vector is the probability vector $p$ on these points.   We have, of
course, the constraints that the probabilities are nonnegative and
sum to one ($d$ inequality constraints and 1 equality constraint),
but suppose we also want both the mean and the median to be exactly
$(d + 1) / 2$.

The mean constraint is an equality constraint
$$
   \sum_{k = 1}^d k p_k = \frac{d + 1}{2}.
$$
The median constraint is two inequality constraints
\begin{equation} \label{eq:median-two}
\begin{split}
   \sum_{k = 1}^{\lfloor (d + 1) / 2 \rfloor} p_k \ge \frac{1}{2}
   \\
   \sum_{k = \lceil (d + 1) / 2 \rceil}^d p_k \ge \frac{1}{2}
\end{split}
\end{equation}
In case $d$ is even, so $(d + 1) / 2$ is not an integer, these two
constraints must actually be satisfied with equality (hence are
\emph{implied equality constraints}) because of the
constraint that the probabilities sum to one.
In case $d$ is odd, so $(d + 1) / 2$ is an integer, these two
constraints can be satisfied with strict inequality, so they
are not equality constraints, either implied or explicit.

We can specify them as inequality constraints and leave it to
the R function \texttt{linearity} to figure out when they are implied equality
constraints.  But that is the step that does not scale.  In case $d$ is even,
if we replace the two inequality constraints \eqref{eq:median-two}
by the single inequality constraint
\begin{equation} \label{eq:median-one}
   \sum_{k = 1}^{\lfloor (d + 1) / 2 \rfloor} p_k = \frac{1}{2}
\end{equation}
(caution: this only works for the $d$ even case), then the computer
can skip the call to the \texttt{linearity} function, and this will scale.

Finally, suppose we want the median absolute deviation to be at least $r$.
That gives us one inequality constraint
$$
   \sum_{k = 1}^{\lfloor (d + 1) / 2 - r \rfloor} p_k
   +
   \sum_{k = \lceil (d + 1) / 2 + r \rceil}^d p_k
   \ge
   \frac{1}{2}
$$

Set $d$ and $r$
<<d-and-r>>=
d <- 10
r <- floor((d - 1) / 4)
@

\section{Computational Geometry}

Before we can simulate we must do a dimension reduction,
finding the dimension of the convex polytope and finding a coordinate
system in which the convex polytope has full dimension.
To do that, we use functions
in the R package \texttt{rcdd}, which does computational geometry.

We express the constraints as \eqref{eq:constraints}.
<<cons>>=
y <- 1:d
a2 <- rbind(rep(1, d), y)
b2 <- c(1, (d + 1) / 2)
a1 <- - diag(d)
b1 <- rep(0, d)
a1 <- rbind(a1, as.numeric(2 * y < d + 1), as.numeric(2 * y > d + 1))
b1 <- c(b1, 1 / 2, 1 / 2)
a1 <- rbind(a1, - as.numeric(y <= (d + 1) / 2 - r) -
    as.numeric(y >= (d + 1) / 2 + r))
b1 <- c(b1, - 1 / 2)
@
Now we dump this into \texttt{rcdd}.  The constraint set is represented
by constraints as an H-representation.  The function \texttt{makeH} makes
that.
<<hrep>>=
library(rcdd)
hrep1 <- makeH(a1, b1, a2, b2)
hrep1
@
The first column is a code: 1 indicates an equality constraint,
0 indicates an inequality constraint.  The second column is the right-hand
side vector.  The rest of each row is the negative of some row of $A_1$
or $A_2$.

\subsection{Implied Equality Constraints I} \label{sec:avoid-linearity}

Now we do the linear program \eqref{eq:linprog-one}.  First we modify
the H-representation to have the additional variable $e$, which we
tack onto the end of the state vector.
<<hrep6>>=
hrep6 <- cbind(hrep1, 0)
hrep6[hrep6[ , 1] == 0, d + 3] <- (-1)
@
The reason for $- 1$ rather than $+ 1$ is the way H-representations work
in \texttt{rcdd}.  Compare with the linear program in Section~\ref{sec:initial}
below.  The complete explanation is in the help for the \texttt{lpcdd}
function in the \texttt{rcdd} package.

Then we make the gradient vector for the objective function
<<grad6>>=
grad6 <- c(rep(0, d), 1)
@
This says we want to maximize the dot product of \texttt{grad6} and the
state vector, which is just the last component of the state vector, which
is the variable $e$.

Then we solve the linear program using exact rational arithmetic
<<lp6>>=
lout <- lpcdd(d2q(hrep6), d2q(grad6), minimize = FALSE)
names(lout)
lout$solution.type
lout$optimal.value
@
If we did not have \verb@lout$solution.type@ equal to \texttt{"Optimal"},
this would have indicated that the constraints were actually inconsistent
(the constraint set is empty).  In this case, the \texttt{hitrun} function
should terminate with an explanatory error.

The fact that \verb@lout$optimal.value@ is zero (the reason it is a character
string rather than numeric zero is because of the way that rational numbers
are represented in the \texttt{rcdd} package) says that there are implied
inequality constraints and we do have to use the linearity function to
find out what they are.  In which case we skip to Section~\ref{sec:linearity}
below.

\subsection{Implied Equality Constraints II}

Suppose instead that the user (here us, but in real life a real user using
the \texttt{hitrun} function) had instead specified the equality and inequality
constraints using \eqref{eq:median-one} instead of \eqref{eq:median-two}
<<cons-too>>=
stopifnot(d %% 2 == 0)
a2 <- rbind(rep(1, d), y, as.numeric(y < (d + 1) / 2))
b2 <- c(1, (d + 1) / 2, 1 / 2)
a1 <- - diag(d)
b1 <- rep(0, d)
a1 <- rbind(a1, - as.numeric(y <= (d + 1) / 2 - r) -
    as.numeric(y >= (d + 1) / 2 + r))
b1 <- c(b1, - 1 / 2)
hrep7 <- makeH(a1, b1, a2, b2)
hrep7
@
Then we redo the linear program in Section~\ref{sec:avoid-linearity} above.
<<lpcdd-redo>>=
hrep8 <- cbind(hrep7, 0)
hrep8[hrep8[ , 1] == 0, d + 3] <- (-1)
lout <- lpcdd(d2q(hrep8), d2q(grad6), minimize = FALSE)
names(lout)
lout$solution.type
lout$optimal.value
@
Again, if we did not have \verb@lout$solution.type@ equal to \texttt{"Optimal"},
this would have indicated that the constraints were actually inconsistent
(the constraint set is empty).  In this case, the \texttt{hitrun} function
should terminate with an explanatory error.

The fact that \verb@lout$optimal.value@ is strictly positive
(the reason it is a character
string rather than numeric zero is because of the way that rational numbers
are represented in the \texttt{rcdd} package) says that there are no implied
inequality constraints and we do not have to use the linearity function to
find out what they are.  In which case we skip the following
section (Section~\ref{sec:linearity}) and go directly
to Section~\ref{sec:change} below.  Section~\ref{sec:linearity} does nothing
except make \texttt{hrep2} a copy of \texttt{hrep1} with components converted
to rational arithmetic.

\subsection{Implied Equality Constraints III} \label{sec:linearity}

We now do an operation that is needed for this example when $d$ is even
but not when $d$ is odd.  It is needed if we allow users to input
general constraint matrices and vectors.
This is determination of the implied equality constraints.
<<hrep-too>>=
lout <- linearity(d2q(hrep1))
is.equality <- hrep1[ , 1] == 1
is.equality[lout] <- TRUE
is.equality
@
The constraints that hold with equality (both explicit and implied)
are the ones with the corresponding components of \texttt{is.equality} equal
to \texttt{TRUE}.

Note the operation \texttt{d2q} which provides the H-representation as
GMP (GNU multiple precision) rational values, and makes the \texttt{linearity}
function use infinite precision rational arithmetic.  Hence our computation is
exact.  We use exact rational arithmetic until further notice.

We make a new H-representation with the implied equality constraints
changed to explicit equality constraints.
<<hrep2>>=
hrep2 <- d2q(hrep1)
hrep2[is.equality , 1] <- "1"
hrep2
@

\subsection{Change of Variable} \label{sec:change}

Now we need to deal with equality constraints and inequality constraints
separately.
<<sep>>=
hrep3 <- hrep2[hrep2[ , 1] == "1", , drop = FALSE]
hrep4 <- hrep2[hrep2[ , 1] == "0", , drop = FALSE]
@

\subsubsection{V-Representation}

The equality constraints give us the affine hull of the polytope.
We want to switch from an H-representation of the affine hull (the
equality constraints) to a V-representation (a point in the affine
hull and a set of basis vectors for the tangent space of the affine hull,
the vector space parallel to it).  The R function \texttt{scdd} in
the R package \texttt{rcdd} does this operation.
<<affine-hull>>=
vrep3 <- scdd(hrep3, representation = "H")$output
vrep3
is.line <- vrep3[ , 1] == "1" & vrep3[ , 2] == "0"
is.point <- vrep3[ , 1] == "0" & vrep3[ , 2] == "1"
all(is.point | is.line)
sum(is.point) == 1
@
The codes in the first and second columns are 0 and 1 (in that order) for
points and 1 and 0 (in that order) for directions.  The affine hull of the
convex polytope
is the vector subspace spanned by the directions
translated by the point.  We should have one point and all the rest lines
(directions).  (There are two other codes --- 0 and 0 for rays and 1 and 1
for affine generators --- but we should never have either of them.)
<<coordinates>>=
foo <- vrep3[ , - c(1, 2), drop = FALSE]
origin <- foo[is.point, ]
basis <- foo[is.line, , drop = FALSE]
basis <- t(basis)
origin
basis
@
The transpose is because we want the columns of the matrix \texttt{basis}
to be the basis vectors.
If we denote the vector \texttt{origin} as $u$ and the matrix \texttt{basis}
as $V$, then the transformation $x \mapsto u + V x$ maps
\Sexpr{ncol(basis)}-dimensional space to the affine hull of the convex
polytope in \Sexpr{nrow(basis)}-dimensional space.  We say this transformation
maps ``new coordinates'' to ``old coordinates.''

\subsubsection{An Orthogonal Basis}

<<ortho-basis>>=
dim(basis)
basis <- qgram(basis)
dim(basis)
basis
@

Check that this is indeed orthogonal
<<ortho-basis-check>>=
basis.check <- qmatmult(t(basis), basis)
all(basis.check[row(basis.check) != col(basis.check)] == "0")
diag(basis.check)
@

All off-diagonal elements of the product being zero says the columns
of \texttt{basis} are orthogonal, but the squared Euclidean lengths
not being all equal to one (or even any equal to one) says they are
not unit vectors in the Euclidean sense.  That is because Euclidean
length involves a square root and that would make the numbers irrational
and we want to still use rational arithmetic for a while.

In fact, the R function \texttt{qgram} makes these unit vectors in
the $L^1$ sense rather than in the $L^2$ sense.
<<ortho-basis-L1>>=
apply(qabs(basis), 2, qsum)
@

\begin{center} \LARGE REVISED DOWN TO HERE \end{center}

\subsection{Inequality Constraints in New Coordinates}

The change of variable takes care of the equality constraints.  By
construction $u + V x$ satisfies the equality constraints (in old coordinates)
for all $x$ (for all points in new coordinates).

We now need to make the inequality constraints refer to the new coordinate
system.  If the constraints are $A y \le b$ in the old coordinate system,
then they are $A(u + V x) \le b$ in the new coordinate system, or,
what is equivalent $A V x \le b - A u$.  Thus we need to construct
the matrix $A V$ and the vector $b - A u$.
<<ineq>>=
amat <- qneg(hrep4[ , - c(1, 2), drop = FALSE])
bvec <- hrep4[ , 2]
bvec <- qmq(bvec, qmatmult(amat, cbind(origin)))
amat <- qmatmult(amat, basis)
@

Some of these constraints may be redundant --- implied by some of the
others --- but that is o.~k.  Eliminating redundant constraints is more
trouble than it is worth.  It can be exceedingly time consuming to eliminate
them.  Having redundant inequality constraints that are truly inequality
constraints (which has been assured by our use of the \texttt{linearity}
function), does not affect the correctness of the hit-and-run algorithm.
The redundant constraints have no effect, and checking them only slows
down the hit-and-run algorithm by a little bit.

\subsection{Log Unnormalized Density Function in New Coordinates}

The log unnormalized density function in old coordinates is
$$
   h_{\text{old}}(y) = \sum_{i = 1}^d (\alpha_i - 1) \log(y)
$$
We must have $y_i > 0$ for all components of $y$ for this to make sense.
However, using inexact computer arithmetic we could get very small negative
$y_i$ and hence have to deal with that.  The right thing to do is return
\verb@-Inf@.  This will cause this proposal to be rejected in the Metropolis
algorithm.

The log unnormalized density function in new coordinates is
$$
   h_{\text{new}}(x) = h_{\text{old}}(u + V x)
$$
where $u$ and $V$ are as defined in Section~\ref{sec:change} and are
called \texttt{origin} and \texttt{basis}, respectively, in R and C code.
This will work correctly with inexact computer arithmetic if $h_{\text{old}}$
is defined so as to work correctly, as explained in the preceding paragraph.

\subsection{Output Function in New Coordinates}

The output function in old coordinates is
$$
   f_{\text{old}}(y) = O y
$$
where $O$ is the matrix \texttt{outmat} in R and C code.
Hence in new coordinates it is
$$
   f_{\text{new}}(y) = O (u + V x) = O u + O V x
$$
where, as in the preceding section, $u$ and $V$ are as defined in
Section~\ref{sec:change}.

\subsection{Initial State} \label{sec:initial}

There is one remaining issue involving computational geometry:
finding a starting point for the Markov chain if one is not supplied,
which can be any point in the constraint set (in new coordinates).

So we use linear programming.  To do this we solve
the following linear program
\begin{align*}
    \text{\normalfont maximize} & \quad e
    \\
    \text{\normalfont subject to} & \quad A x + e \le b
\end{align*}
in which the state is the vector $(x, e)$ where $x$ is the state of the
given problem (in new coordinates) and $e$ is another scalar variable,
and in which the inequality is interpreted coordinatewise.
Given that we know that none of the inequality constraints is an implied
equality constraint it must be that there exist points $x$ such that
$A x < b$ (where, again, inequality is interpreted coordinatewise)
holds hence $A x + e \le b$ holds for some strictly positive $e$,
assuming that the constraint set is actually nonempty.
The linear program then finds $x$ and $e$ such that $e$ is as large as
possible, thus finding the relative interior point that is farthest from
the boundary.
<<lp>>=
hrep5 <- cbind("0", bvec, qneg(amat), "-1")
grad5 <- c(rep("0", ncol(amat)), "1")
lout <- lpcdd(hrep5, grad5, minimize = FALSE)
names(lout)
lout$solution.type
lout$optimal.value
@
If \verb@lout$solution.type@ is \verb@"Optimal"@
and \verb@lout$optimal.value@ is a positive number, then we have found
a point in the relative interior of the convex polytope (in new coordinates).
Otherwise the convex polytope is
the empty set (the constraints are inconsistent), in which case we have to
give an error message (the user has specified the problem incorrectly).

When we have an optimal solution (a point in the polytope), it is
<<lp-point>>=
x <- lout$primal.solution
x <- x[- length(x)]
x
@
(a point in new coordinates).

Let us check that this point does satisfy the constraints
<<relative-interior-check>>=
qmq(bvec, as.vector(qmatmult(amat, cbind(x))))
@
All constraints are indeed slack.  The point \texttt{x} is in the
relative interior of the constraint set in the new coordinates.
It is a possible starting value for the Markov chain.

\subsection{Conversion from Rational to Floating Point}

Now we convert the arguments to the MCMC function to conventional
computer so-called real numbers.
<<convert>>=
origin <- q2d(origin)
basis <- q2d(basis)
bvec <- q2d(bvec)
amat <- q2d(amat)
x <- q2d(x)
bvec
amat
round(x, 4)
@

\section{Hit-and-Run Sampler}

How does hit-and-run work?  It generates a random direction (we use the
direction along a mean-zero normal random vector), then calculates the
section of the line through the current position in that direction that
lies in the constraint set (the constraint set in the new coordinates
determined by \texttt{amat} and \texttt{bvec}).

\subsection{Proposal Line Segment}

To calculate the proposal, we need to know
the maximum and minimum values of $s$ such that
$$
   A (x + s z) \le b
$$
holds where $x$ is the current position and $z$ is the mean-zero normal
random vector.  Since this is the same as
$$
   s A z \le b - A x
$$
we find the range of $s$ values such that this holds.
Write
\begin{align*}
   q & = A z
   \\
   r & = b - A x
\end{align*}
so the inequalities are
\begin{equation} \label{eq:ineq}
   s q_i \le r_i, \qquad i = 1, \ldots, n
\end{equation}
where $n$ is the row dimension of \texttt{amat} and the length
of \texttt{bvec}.
We know that the current state $x$ satisfies the constraints $A x \le b$,
hence \eqref{eq:ineq} is satisfied when $s = 0$.  When $q_i < 0$ dividing
through by $q_i$ reverses the inequality, thus the inequalities \eqref{eq:ineq}
become
\begin{align*}
   s & \le r_i / q_i, \qquad i \in D \opand q_i > 0
   \\
   s & \ge r_i / q_i, \qquad i \in D \opand q_i < 0
\end{align*}
(where $D$ is given by \eqref{eq:state-space}).  So, defining
\begin{align*}
   s_{\text{max}} & = \min_{\substack{i \in D \\ q_i > 0}} \frac{r_i}{q_i}
   \\
   s_{\text{min}} & = \max_{\substack{i \in D \\ q_i < 0}} \frac{r_i}{q_i}
\end{align*}
the set of points of the form $x + s z$ that lie in the convex polytope
are those for which $s_{\text{min}} \le s \le s_{\text{max}}$.
And (as mentioned above) we always have $s_{\text{min}} < 0 < s_{\text{max}}$.

\subsection{Proposal Direction Distribution} \label{sec:proposal}

The proposal direction distribution does not matter, so long as it proposes
directions that span the space (of new coordinates).  At least it does not
affect the correctness of the hit-and-run algorithm.  It may affect the
efficiency (how long one needs to run the sample to get a certain accuracy
of estimation).  For now we just use a standard multivariate normal
distribution (mean vector zero, variance matrix the identity)
in new coordinates.

\begin{thebibliography}{}

\bibitem[Geyer and Meeden(2013)]{geyer-meeden}
Geyer, C.~J. and Meeden, G.~D. (2013).
\newblock Asymptotics for constrained Dirichlet distributions.
\newblock \emph{Bayesian Analysis}, \textbf{8}, 89--110.

\end{thebibliography}

\end{document}

\begin{center} \LARGE REVISED DOWN TO HERE \end{center}

